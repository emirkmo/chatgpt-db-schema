{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4376bfca-cec3-4253-b9aa-1d4f0f73562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def load_api_key(path: str = '../.env') -> None:\n",
    "    with open(path,'r') as keyfile:\n",
    "        openai.api_key = keyfile.read().strip('\\n').strip().split('=')[1]\n",
    "load_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bb72aa74-a857-4525-87bd-12939b2f31a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Protocol, Required, Any\n",
    "from functools import reduce\n",
    "import json \n",
    "\n",
    "from pydantic.dataclasses import dataclass, Field\n",
    "from pydantic.main import ModelMetaclass\n",
    "from pydantic import create_model\n",
    "\n",
    "from enum import StrEnum, auto\n",
    "from typing import TypedDict\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ChatRoles(StrEnum):\n",
    "    \"\"\"Chat response roles in chat gpt api\"\"\"\n",
    "    system = auto()\n",
    "    user = auto()\n",
    "    assistant = auto()\n",
    "    \n",
    "class FormattedChatMessage(TypedDict):\n",
    "    role: ChatRoles.user\n",
    "    content: str\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class ChatMessage:\n",
    "    \"\"\"Chat message content in chat gpt api\"\"\"\n",
    "    role: ChatRoles = ChatRoles.user\n",
    "    content: str = \"\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.content == \"\":\n",
    "            raise ValueError(\"Content should not be empty, else we waste tokens!\")\n",
    "            \n",
    "    def _minify_prompt(self) -> str:\n",
    "        return (self.content.replace('  ','').strip()   # remove visual indent\n",
    "            .replace(\"\\n\", \" \").strip()   # remove newlines\n",
    "            .replace(\"<br>\",\"\\n\"))  # add newlines for paragraph breaks only.\n",
    "    \n",
    "    def formatted(self) -> FormattedChatMessage:\n",
    "        return {\"role\": self.role.value, \"content\": self._minify_prompt()}\n",
    "    \n",
    "USER_DEFAULT_PROMPT = \"\"\"\n",
    "    You are going to give detailed helpful suggestions to improve the cohesion, readability,\n",
    "    and ease of use of a proposed SQL database table schema. I will provide a JSON formatted prompt\n",
    "    starting with a table name, a one-sentence description of the contents of the table\n",
    "    and what the expected usecase for the data that will be uploaded to this table.\n",
    "    The usecases are usually analytics or diagnostics for data uploaded by a set of devices sold by a business.\n",
    "    The prompt will continue with a list of proposed column names, data type of the column,\n",
    "    and description of the content. <br>\n",
    "    \n",
    "    Using your expertise in database management, data analysis,\n",
    "    and speaking as someone who must ensure that the names of data fields are consistent,\n",
    "    descriptive and easy to understand, you will propose helpful changes to the JSON formatted\n",
    "    table schema, while concisely explaining your reasoning behind your proposed changes. You\n",
    "    must answer in a concise and space efficient way, providing deeper reasoning if later asked. <br>\n",
    "    \n",
    "    When proposing changes, you will ensure that the column names use a uniform pythonic\n",
    "    format with underscores \"_\" to connect words and mention the units of the measurement\n",
    "    if relevant. For example, columns counting something should end with \"_counts\", a time measurement\n",
    "    should include \"_seconds\" or \"_ms\" depending on the data measurement unit. <br>\n",
    "    \n",
    "    You will spend the most effort making absolutely sure that the column names are descriptive\n",
    "    and specific, the column names are easy to read and understand by users who may\n",
    "    not be familiar with the underlying device or data, in general are easy to read and understand at a glance,\n",
    "    and that they are uniform in style, formatting, structure, and follow a uniform naming convention.\n",
    "    This means that the column names and descriptions are not overly generic, unclear, or unspecific.\n",
    "    They do not use different words to refer to the same things.\n",
    "    You will also check the spelling and grammar of the descriptions of the columns. <br>\n",
    "    \n",
    "    If you find that you need to propose a large amount of changes, you will limit yourself to only\n",
    "    proposing what to change, without explaining the reasoning behind it. If you find that the prompt with\n",
    "    the table columns and descriptions is already very good with a uniform style and clear naming conventions,\n",
    "    you can explain more of your reasoning since you will only propose minimal changes.\n",
    "\"\"\"\n",
    "\n",
    "ASSISTANT_DEFAULT_RESPONSE = \"\"\"Sure, I can help with improving the SQL schema.\n",
    "    Please provide me with the table name, description, and column names with data type and description,\n",
    "    in JSON format, so I can propose useful suggestions for improving the SQL schema.\"\"\"\n",
    "\n",
    "def compose_prompt(*messages: list[ChatMessage]) -> list[FormattedChatMessage]:\n",
    "    _messages = itertools.chain.from_iterable(messages)\n",
    "    return [message.formatted() for message in _messages]\n",
    "\n",
    "    \n",
    "def get_init_prompt() -> list[ChatMessage]:\n",
    "    system = ChatMessage(\n",
    "        role=ChatRoles.system, \n",
    "        content=\"You are a helpful assistant. Answer as concisely as possible.\")\n",
    "    \n",
    "    user = ChatMessage(\n",
    "        role=ChatRoles.user,\n",
    "        content=USER_DEFAULT_PROMPT)\n",
    "    \n",
    "    assistant = ChatMessage(\n",
    "        role=ChatRoles.assistant,\n",
    "        content=ASSISTANT_DEFAULT_RESPONSE)\n",
    "    \n",
    "    return [system,user,assistant]\n",
    "\n",
    "\n",
    "class ColumnSpecification(TypedDict):\n",
    "    type: str\n",
    "    description: str\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class TemplateTable:\n",
    "    col1_name: str = Field(description='col1 description text.', default='')\n",
    "    col2_name: str = Field(description='col2 description.', default='')\n",
    "    \n",
    "    # Raise error if someone tries to instantiate the template..\n",
    "    def __post_init__(self):\n",
    "        raise NotImplementedError(\"This is just a template for reference!\")\n",
    "    \n",
    "\n",
    "class Contract(TypedDict):\n",
    "    table: str\n",
    "    table_description: str\n",
    "    columns: dict[str|ColumnSpecification]\n",
    "    \n",
    "    \n",
    "def to_snake_case(str) -> str:\n",
    "    \"\"\"Convert CamelCase to snake_case (well actually `camel_case`).\"\"\"\n",
    "    return reduce(lambda x, y: x + ('_' if y.isupper() else '') + y, str).lower()\n",
    "    \n",
    "class PydanticSchema(Protocol):\n",
    "    __pydantic_model__: ModelMetaclass\n",
    "    \n",
    "class HasPydanticSchema(Protocol):\n",
    "    \"\"\"Interface for pydantic schema\"\"\"\n",
    "    @staticmethod\n",
    "    def schema(by_alias: bool, ref_template: 'unicode') -> dict[str | Any]:\n",
    "        ...\n",
    "\n",
    "\n",
    "\n",
    "KNOWN_TYPES = {\n",
    "    \"int\": int,\n",
    "    \"integer\": int,\n",
    "    \"float\": float,\n",
    "    \"number\": float,\n",
    "    \"str\": str,\n",
    "    \"string\": str,\n",
    "}\n",
    "\n",
    "PYDANTIC_TYPES = {\n",
    "    int: \"integer\",\n",
    "    float: \"float\",\n",
    "    str: \"string\",\n",
    "}\n",
    "\n",
    "def type_convert(type_str: str) -> str:\n",
    "    if type_str in KNOWN_TYPES:\n",
    "        return PYDANTIC_TYPES[KNOWN_TYPES[type_str]]\n",
    "    return type_str\n",
    "        \n",
    "\n",
    "\n",
    "def dynamically_create_pydantic_model(table_name: str, fields=list[tuple[str, type | str, str]]) -> HasPydanticSchema:\n",
    "    \"\"\"Create a pydantic model table from dynamically input fields.\"\"\"\n",
    "    return create_model(\n",
    "        table_name,\n",
    "        **{\n",
    "            name:(KNOWN_TYPES[typ], Field(description=desc))\n",
    "            for (name, typ, desc) in fields\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def make_contract(table: HasPydanticSchema, description: str = \"This is a table with data.\") -> Contract:\n",
    "    schema = table.schema()\n",
    "    table_name = {'table': to_snake_case(schema['title']),\n",
    "                 'table_description': description}\n",
    "    columns = {field_name: {\"type\": type_convert(typ_format), \"description\": properties[\"description\"]}\n",
    "               for field_name, properties in schema[\"properties\"].items()\n",
    "               if (typ_format := properties.get('format', properties['type'])) is not None }\n",
    "    \n",
    "    return table_name | {\"columns\": columns}\n",
    "\n",
    "class ChatModels(StrEnum):\n",
    "    gpt_turbo = 'gpt-3.5-turbo'\n",
    "    davinci_02 = 'text-davinci-002'\n",
    "    code_davinci = 'code-davinci-002'  # 8000 tokens!\n",
    "    \n",
    "def make_final_prompt(contract: Contract, *additional_prompts: ChatMessage) -> list[FormattedChatMessage]:\n",
    "    table_schema_prompt = ChatMessage(content=json.dumps(contract))\n",
    "    final_prompt = compose_prompt(get_init_prompt(), [table_schema_prompt], additional_prompts)\n",
    "    return final_prompt\n",
    "\n",
    "def ask_chatgpt(prompt: list[FormattedChatMessage], model: ChatModels = ChatModels.gpt_turbo) -> openai.openai_object.OpenAIObject:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=prompt\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "def get_feedback(contract: Contract, model: ChatModels = ChatModels.gpt_turbo) -> openai.openai_object.OpenAIObject:\n",
    "    final_prompt = make_final_prompt(contract)\n",
    "    return ask_chatgpt(final_prompt)\n",
    "\n",
    "def pretty_print_response(feedback: openai.openai_object.OpenAIObject):\n",
    "    print(feedback.choices[0].message.content)\n",
    "    return feedback.choices[0]\n",
    "\n",
    "def pydantic_model_from_contract(contract: Contract) -> HasPydanticSchema:\n",
    "    fields = [(colname, properties['type'], properties['description']) for colname, properties in contract['columns'].items()]\n",
    "    return dynamically_create_pydantic_model(contract['table'], fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c931206e-c46c-4f8e-86e9-123e5aa47647",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AddStats:\n",
    "    add_detections: int = Field(description='total number of audio distortions detected.')\n",
    "    add_detection_class: str = Field(description='Audo distortion detected class.')\n",
    "    add_classes: str = Field(description=\"comma separated list of distortion classes. For example: 'Transients, Spikes'.\") \n",
    "    add_transients_count: int = Field(description=\"Total number of Transients detected, in counts.\") \n",
    "    add_spikes_count: float = Field(description=\"Total number of spikes detected, in counts.\")\n",
    "    \n",
    "contract = make_contract(AddStats.__pydantic_model__, description=\"Audio distortion detection stats from the microphones of our cameras.\")\n",
    "#new_contract_feedback = get_feedback(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cdb75eb1-94cb-42f0-a849-165b72dafdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the prompt. Here are my proposed changes to improve the schema:\n",
      "\n",
      "- Rename the table to \"audio_distortion_detection_stats\" to make it more descriptive and easier to understand at a glance.\n",
      "- Rename the column \"add_detections\" to \"total_distortion_detections\" to be more specific and descriptive.\n",
      "- Rename the column \"add_detection_class\" to \"distortion_detection_class\" to follow a uniform naming convention and be more descriptive.\n",
      "- Rename the column \"add_classes\" to \"distortion_classes\" to follow a uniform naming convention and be clearer in meaning.\n",
      "- Add a new column called \"camera_id\" with data type \"integer\" and description \"ID of the camera that generated the audio data\" to make it easier to associate data with specific cameras in the future.\n",
      "- Rename the column \"add_transients_count\" to \"total_transient_counts\" to follow a uniform naming convention and be more specific.\n",
      "- Change the data type of the \"add_spikes_count\" column from \"float\" to \"integer\" since it's unlikely for \"spikes\" to be in decimal form.\n",
      "\n",
      "Let me know if you have any questions on my proposed changes.\n"
     ]
    }
   ],
   "source": [
    "output = pretty_print_response(new_contract_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "71bb0c7d-a86f-4213-9b7a-392d0eab4152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for providing the JSON. Here are some suggestions for improving the SQL schema. \n",
      "\n",
      "1. Rename the table name to \"audio_distortion_detection\" to be more descriptive and consistent with the content of the table. \n",
      "\n",
      "2. Rename \"add_detections\" column to \"total_detections\" to be more specific and easy to understand. \n",
      "\n",
      "3. Rename \"add_detection_class\" to \"detection_class\" to be less generic and more consistent with column naming.\n",
      "\n",
      "4. Rename \"add_classes\" to \"distortion_classes\" for a more descriptive column name. \n",
      "\n",
      "5. Modify the \"add_transients_counts\" column to \"transients_detected\" for consistent column naming convention.\n",
      "\n",
      "6. Change the data type of \"add_spikes_count\" from number to integer for uniformity and consistency.\n",
      "\n",
      "7. Add a new column \"timestamp\" with the data type of \"timestamp\" to capture the date and time of the audio distortion detection. This will help in data analysis and provide more context for the data.\n",
      "\n",
      "Overall, these changes aim to make the schema more descriptive, specific, and easier to understand for the end-users.\n"
     ]
    }
   ],
   "source": [
    "print(contract_feedback.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b0e0d-90b4-4121-a9b6-116e67ba5184",
   "metadata": {},
   "source": [
    "# After fixing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e1687-961a-48a3-8599-83ae089860ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "@dataclass\n",
    "class AudioDistortionDetectionStats:\n",
    "    total_distortion_detections: int = Field(description='total number of audio distortions detected.')\n",
    "    distortion_detection_class: str = Field(description='Audo distortion detected class.')\n",
    "    distortion_classes: str = Field(description=\"Comma separated list of distortion classes. For example: 'Transients, Spikes'.\") \n",
    "    total_transients_count: int = Field(description=\"Total number of Transients detected, in counts.\") \n",
    "    total_spikes_count: int = Field(description=\"Total number of spikes detected, in counts.\")\n",
    "    timestamp: str = Field(description=\"String formatteed timestamp at date and time of the distortion detection.\")\n",
    "    camera_id: int = Field(description=\"ID of the camera that generated the audio data.\")\n",
    "    \n",
    "fixed_contract = make_contract(AudioDistortionDetectionStats.__pydantic_model__, \n",
    "                               description=\"Audio distortion detection stats from the microphones of our cameras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a549c432-740a-4908-8958-27aa6112a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my suggestions for improving the SQL schema for the \"audio_distortion_detection_stats\" table:\n",
      "\n",
      "1. Change the column name \"total_distortion_detections\" to \"total_distortion_detections_counts\" to make it more specific and in line with the naming convention suggested in the prompt.\n",
      "2. Change the column name \"distortion_detection_class\" to \"detected_distortion_class\" for consistency in column naming.\n",
      "3. Change the column name \"distortion_classes\" to \"detected_distortion_classes\" for consistency and clarity in column naming.\n",
      "4. Change the column name \"total_transients_count\" to \"transients_counts\" for consistency in column naming.\n",
      "5. Change the column name \"total_spikes_count\" to \"spikes_counts\" for consistency in column naming.\n",
      "6. Change the data type of the \"timestamp\" column from \"date-time\" to \"timestamp\" for consistency and clarity in data types.\n",
      "7. Keep the \"camera_id\" column name and data type as is since they are already clear and specific.\n",
      "\n",
      "Overall, these changes will help to make the column names more specific and easier to read and understand for someone who is not familiar with the underlying device or data.\n"
     ]
    }
   ],
   "source": [
    "fixed_contract_feedback = get_feedback(fixed_contract)\n",
    "_ = pretty_print_response(fixed_contract_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "911f6587-c22d-4954-a809-252f837c272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "@dataclass\n",
    "class AudioDistortionDetectionStats:\n",
    "    total_distortion_detections: int = Field(description='total number of audio distortions detected.')\n",
    "    detected_distortion_class: str = Field(description='Audo distortion detected class.')\n",
    "    detected_distortion_classes: str = Field(description=\"Comma separated list of distortion classes. For example: 'Transients, Spikes'.\") \n",
    "    transients_count: int = Field(description=\"Total number of Transients detected, in counts.\") \n",
    "    spikes_count: int = Field(description=\"Total number of spikes detected, in counts.\")\n",
    "    timestamp: datetime.datetime = Field(description=\"Timestamp at date and time of the distortion detection.\")\n",
    "    camera_id: int = Field(description=\"ID of the camera that generated the audio data.\")\n",
    "    \n",
    "fixed_contract_2 = make_contract(AudioDistortionDetectionStats.__pydantic_model__, \n",
    "                               description=\"Audio distortion detection stats from the microphones of our cameras.\")\n",
    "\n",
    "\n",
    "additional_messages = [ChatMessage(role=ChatRoles.assistant, content=fixed_contract_feedback.choices[0].message.content.replace(\"\\n\",\"<br>\")),\n",
    " ChatMessage(content=f\"I fixed it according to your suggestions. Do you see any other mistakes? Please also check spelling and grammar. {json.dumps(fixed_contract_2)}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "180b87aa-aeb6-43f2-8b51-c012f49498e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Here are my suggestions for improving the SQL schema for the \"audio_distortion_detection_stats\" table:\\n\\n1. Change the column name \"total_distortion_detections\" to \"total_distortion_detections_counts\" to make it more specific and in line with the naming convention suggested in the prompt.\\n2. Change the column name \"distortion_detection_class\" to \"detected_distortion_class\" for consistency in column naming.\\n3. Change the column name \"distortion_classes\" to \"detected_distortion_classes\" for consistency and clarity in column naming.\\n4. Change the column name \"total_transients_count\" to \"transients_counts\" for consistency in column naming.\\n5. Change the column name \"total_spikes_count\" to \"spikes_counts\" for consistency in column naming.\\n6. Change the data type of the \"timestamp\" column from \"date-time\" to \"timestamp\" for consistency and clarity in data types.\\n7. Keep the \"camera_id\" column name and data type as is since they are already clear and specific.\\n\\nOverall, these changes will help to make the column names more specific and easier to read and understand for someone who is not familiar with the underlying device or data.'}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_messages[0].formatted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b8e0a75c-56cb-46ee-830e-c68f3a550ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The revised JSON is looking good, and I don't see any further mistakes. The spelling and grammar in the descriptions of the columns are clear and correct, making the schema easier to follow for future users who may not be familiar with the underlying device or data. The changes we've made will help ensure that the column names and descriptions are universally understandable, easy to read and not confusing, and follow a uniform naming convention.\n"
     ]
    }
   ],
   "source": [
    "final_prompt = make_final_prompt(fixed_contract, *additional_messages)\n",
    "fixed_contract_2_feedback = ask_chatgpt(final_prompt)\n",
    "#fixed_contract_2_feedback = get_feedback(fixed_contract, *additional_messages)\n",
    "response_2 = pretty_print_response(fixed_contract_2_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e8508f-4ab0-4a9a-9224-9b11e5cc5ecc",
   "metadata": {},
   "source": [
    "# WOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9e7e92fd-c735-4648-a152-894e34fb7f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"completion_tokens\": 86,\n",
      "  \"prompt_tokens\": 1242,\n",
      "  \"total_tokens\": 1328\n",
      "}\n",
      "Cost: $0.005312 or SEK 0.05312 kr.\n"
     ]
    }
   ],
   "source": [
    "#\t$0.002 / 1K tokens\n",
    "def get_cost(tokens: int, cost: float = 0.002/1000) -> float:\n",
    "    return tokens * 0.002/1000\n",
    "\n",
    "print(fixed_contract_2_feedback.usage)\n",
    "cost = get_cost(sum(fixed_contract_2_feedback.usage.values()))\n",
    "print(f\"Cost: ${cost} or SEK {cost*10} kr.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65d016-a00d-4458-b45e-a19cede27a69",
   "metadata": {},
   "source": [
    "### **Do you store the data that is passed into the API?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a9a02-f7c6-471d-b2a8-069c502cc556",
   "metadata": {},
   "source": [
    "As of March 1st, 2023, we retain your API data for 30 days but\n",
    "no longer use your data sent via the API to improve our models. \n",
    "\n",
    "Learn more in our [data usage policy](https://openai.com/policies/usage-policies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3db1a-833f-47e3-8446-0fc766c001d1",
   "metadata": {},
   "source": [
    "### Content co-authored with the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e455ff-c310-4ed8-a621-e480b50f915c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Creators who wish to publish their first-party written content (e.g., a book, compendium of short stories) created in part with the OpenAI API are permitted to do so under the following conditions:\n",
    "\n",
    "    The published content is attributed to your name or company.\n",
    "    The role of AI in formulating the content is clearly disclosed in a way that no reader could possibly miss, and that a typical reader would find sufficiently easy to understand.\n",
    "    Topics of the content do not violate OpenAI’s Content Policy or Terms of Use, e.g., are not related to political campaigns, adult content, spam, hateful content, content that incites violence, or other uses that may cause social harm.\n",
    "    We kindly ask that you refrain from sharing outputs that may offend others.\n",
    "\n",
    "For instance, one must detail in a Foreword or Introduction (or some place similar) the relative roles of drafting, editing, etc. People should not represent API-generated content as being wholly generated by a human or wholly generated by an AI, and it is a human who must take ultimate responsibility for the content being published.\n",
    "\n",
    "Here is some stock language you may use to describe your creative process, provided it is accurate:\n",
    "\n",
    "    The author generated this text in part with GPT-3, OpenAI’s large-scale language-generation model. Upon generating draft language, the author reviewed, edited, and revised the language to their own liking and takes ultimate responsibility for the content of this publication."
   ]
  },
  {
   "cell_type": "raw",
   "id": "70110c97-535e-475d-8086-4dbb701b04d9",
   "metadata": {},
   "source": [
    "Emir Karamehmetoglu generated this text in part with GPT-3, OpenAI’s large-scale language-generation model. Upon generating draft language, the author reviewed, edited, and revised the language to their own liking and takes ultimate responsibility for the content of this publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cbc01-51b3-4146-849a-e30107c368e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatgpt]",
   "language": "python",
   "name": "conda-env-chatgpt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
